{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/home/peterr/macocu/task11/010_results.jsonl'), PosixPath('/home/peterr/macocu/task11/011_results.jsonl'), PosixPath('/home/peterr/macocu/task11/008_results.jsonl'), PosixPath('/home/peterr/macocu/task11/012_results_nonslavic.jsonl'), PosixPath('/home/peterr/macocu/task11/012_results.jsonl'), PosixPath('/home/peterr/macocu/task11/013_results_slavic_asr.jsonl')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Speaker_gender', 'Speaker_name', 'Speaker_age_group',\n",
       "       'Party_status'], dtype=object)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "p = Path(\".\")\n",
    "files = list(p.resolve().rglob(\"0*.jsonl\"))\n",
    "print(files)\n",
    "\n",
    "df = pd.concat([pd.read_json(f, orient=\"records\", lines=True) for f in files], ignore_index=True)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "df[\"accuracy\"] = df.apply(\n",
    "    lambda row: accuracy_score(row[\"y_true\"], row[\"y_pred\"]), axis=1\n",
    ")\n",
    "df[\"macroF1\"] = df.apply(\n",
    "    lambda row: f1_score(row[\"y_true\"], row[\"y_pred\"], average=\"macro\"), axis=1\n",
    ")\n",
    "\n",
    "def assign_model(row):\n",
    "    try:\n",
    "        return row[\"train_config\"][\"model_name_or_path\"]\n",
    "    except:\n",
    "        return \"/\".join(row[\"model_name_or_path\"].split(\"/\")[-2].split(\"_\")[0:2])\n",
    "\n",
    "df[\"model\"] = df.apply(assign_model, axis=1)\n",
    "df.shape\n",
    "df.output_column.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrr}\n",
      "\\toprule\n",
      "                                        model &     eval\\_file &  accuracy &   macroF1 \\\\\n",
      "\\midrule\n",
      "       facebook/wav2vec2-large-960h-lv60-self &  012\\_test.csv &  0.590000 &  0.587285 \\\\\n",
      "  facebook/wav2vec2-large-slavic-voxpopuli-v2 &  012\\_test.csv &  0.590000 &  0.587285 \\\\\n",
      " classla/wav2vec2-large-slavic-parlaspeech-hr &  012\\_test.csv &  0.590000 &  0.587285 \\\\\n",
      " classla/wav2vec2-large-slavic-parlaspeech-hr &  012\\_test.csv &  0.626667 &  0.625928 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[(df.output_column == \"Party_status\") & df.eval_file.str.contains(\"test\"), \"model eval_file accuracy macroF1\".split()].to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us only keep rows that were calculated on test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df.eval_file.str.contains(\"test\")]\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = df.groupby([\n",
    "\"output_column\", \n",
    "\"model\", \n",
    "\"eval_file\", \n",
    "\"clip_seconds\"\n",
    "]).agg(\n",
    "    {\"macroF1\": \"mean\", \"accuracy\": \"mean\"}\n",
    ").reset_index()\n",
    "\n",
    "print(gb.to_markdown())\n",
    "\n",
    "gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only `Party_status` experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    (df.output_column == \"Party_status\") &\n",
    "    df.eval_file.str.contains(\"test\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"science no-latex\".split())\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "sns.barplot(x=\"output_column\", y=\"accuracy\",ci=\"sd\", data=df[df.eval_file.str.contains(\"test\")], hue=\"clip_seconds\", ax=ax)\n",
    "plt.ylim((0.5, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f6f5766036ee03d059e365a942add07f79c17033585e9357ee8157d52fe6bb9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
