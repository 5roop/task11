{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import example_eval_config, example_train_config, train_model, eval_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-4e4c237abd178dbd\n",
      "Reusing dataset csv (/home/peterr/.cache/huggingface/datasets/csv/default-4e4c237abd178dbd/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40683e81ed1947ffb32c68aa3772e677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:52: FutureWarning: Loading a tokenizer inside Wav2Vec2Processor from a config that does not include a `tokenizer_class` attribute is deprecated and will be removed in v5. Please add `'tokenizer_class': 'Wav2Vec2CTCTokenizer'` attribute to either your `config.json` or `tokenizer_config.json` file to suppress this warning: \n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-4e4c237abd178dbd/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-88f43f5345a6720b.arrow\n",
      "Parameter 'function'=<function eval_model.<locals>.predict at 0x7fc28b7d2ee0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "082d9c3bd93b495588274e69eb14ea37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for clip in [-1, 2]:\n",
    "    train_config = {\n",
    "        'model_name_or_path': 'facebook/wav2vec2-large-slavic-voxpopuli-v2',\n",
    "        'TASK': 'NEW_GENDER_2s' if clip==2 else \"NEW_GENDER\",\n",
    "        'NUM_EPOCH': 2,\n",
    "        'data_files': {\n",
    "            'train': '001_gender_train.csv',\n",
    "            'validation': '001_gender_dev.csv'\n",
    "            },\n",
    "        \"clip_seconds\": clip,\n",
    "        \"output_column\": \"Speaker_gender\"\n",
    "    }\n",
    "\n",
    "    OUTPUT_DIR = \"models/facebook_wav2vec2-large-slavic-voxpopuli-v2_NEW_GENDER_\" \n",
    "    if clip == 2:\n",
    "        OUTPUT_DIR += \"2s_\"\n",
    "\n",
    "    for split in \"dev test\".split():\n",
    "        config = {\n",
    "            \"output_column\": \"Speaker_gender\",\n",
    "            \"model_name_or_path\": OUTPUT_DIR+\"/checkpoint-250\",\n",
    "            \"eval_file\": f\"001_gender_{split}.csv\",\n",
    "            \"clip_seconds\": clip,\n",
    "            \"train_config\": train_config\n",
    "        }\n",
    "        y_true, y_pred = eval_model(config)\n",
    "\n",
    "        results.append({**config, \"y_true\": y_true, \"y_pred\": y_pred})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: speaker ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for clip in [-1, 2]:\n",
    "    train_config = {\n",
    "        'model_name_or_path': 'facebook/wav2vec2-large-slavic-voxpopuli-v2',\n",
    "        'TASK': 'NEW_SPEAKER_ID_2s' if clip==2 else \"NEW_SPEAKER_ID\",\n",
    "        'NUM_EPOCH': 2,\n",
    "        'data_files': {\n",
    "            'train': '003_speaker_id_train_for_datasets.csv',\n",
    "            'validation': '003_speaker_id_test_for_datasets.csv'\n",
    "            },\n",
    "        \"clip_seconds\": clip,\n",
    "        \"output_column\": \"Speaker_name\"\n",
    "    }\n",
    "\n",
    "    OUTPUT_DIR = train_model(train_config)\n",
    "\n",
    "    for split in \"dev test\".split():\n",
    "        config = {\n",
    "            \"output_column\": \"Speaker_name\",\n",
    "            \"model_name_or_path\": OUTPUT_DIR+\"/checkpoint-1250\",\n",
    "            \"eval_file\": f\"003_speaker_id_{split}_for_datasets.csv\",\n",
    "            \"clip_seconds\": clip,\n",
    "            \"train_config\": train_config,\n",
    "        }\n",
    "        y_true, y_pred = eval_model(config)\n",
    "\n",
    "        results.append({**config, \"y_true\": y_true, \"y_pred\": y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data=results)\n",
    "df.to_json(\"008_results.jsonl\", origin=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Age group - males"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for clip in [-1]:\n",
    "    train_config = {\n",
    "        'model_name_or_path': 'facebook/wav2vec2-large-slavic-voxpopuli-v2',\n",
    "        'TASK': 'NEW_AGE_ID_2s' if clip==2 else \"NEW_AGE_ID\",\n",
    "        'NUM_EPOCH': 15,\n",
    "        'data_files': {\n",
    "            'train': '006_age_train.csv',\n",
    "            'validation': '006_age_test.csv'\n",
    "            },\n",
    "        \"clip_seconds\": clip,\n",
    "        \"output_column\": \"Speaker_age_group\"\n",
    "    }\n",
    "\n",
    "    OUTPUT_DIR = train_model(train_config)\n",
    "    \n",
    "    for split in \"dev test\".split():\n",
    "        config = {\n",
    "            \"output_column\": \"Speaker_age_group\",\n",
    "            \"model_name_or_path\": OUTPUT_DIR+\"/checkpoint-2250\",\n",
    "            \"eval_file\": f\"006_age_{split}.csv\",\n",
    "            \"clip_seconds\": clip,\n",
    "            \"train_config\": train_config,\n",
    "        }\n",
    "        y_true, y_pred = eval_model(config)\n",
    "\n",
    "        results.append({**config, \"y_true\": y_true, \"y_pred\": y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data=results)\n",
    "df.to_json(\"008_results.jsonl\", origin=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f6f5766036ee03d059e365a942add07f79c17033585e9357ee8157d52fe6bb9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
